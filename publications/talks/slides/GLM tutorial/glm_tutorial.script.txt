############################################################################

## Introduction #############################################################



#############################################################################


=============================================================================

== Truccolo et al. 2005 =====================================================

############################################################################

== Linear model / multiple linear regression ================================


== Nonlinear features OK ====================================================

############################################################################

## GLM point process for spike trains #######################################


##   ########################################################################


== Point process model: =====================================================


== GLM point process models =================================================

############################################################################

== Fitting GLM point-process models    ======================================


== GLM point process model for single unit spiking with ensemble history ====


== Intrinsic history filter =================================================


== Ensemble history filter ==================================================


== Extrinsic covariates: kinematics =========================================

	<3->Rule et al. 2015 found Hatsopoulos normalized "pathlets" and position trajectories to perform equivalently
############################################################################
############################################################################

== Maximum likelihood approach to model fitting =============================


== Minimize the negative log-likelihood =====================================


== Gradient of the negative log-likelihood ==================================

############################################################################

## Regularization ###########################################################


== Regularized GLM  =========================================================


== Regularized GLM: L1 and L2 ===============================================


== Regularized GLM: L1 approximation and L0 =================================


== Regularized GLM: Group lasso =============================================

############################################################################

== Two-layer crossvalidation ================================================

############################################################################

== Regularization paths =====================================================


== Initialization with closed form solution =================================

Fs = 1000.0
N  = 1000 * Fs
for b in linspace(0,10,3):
	for r in linspace(5,150,3):
		print N,b,r
		x = randn(N)
		l = exp(b*x)/Fs
		y = rand(N)<l
		k = mean(y)*Fs
		correction = log(r/k)
		print '\t','correction=',correction
		l = exp(b*x+correction)/Fs
		y = rand(N)<l
		print '\t',mean(y)*Fs,sum(y)
		print '\t',mean(x[y])


=============================================================================

## Truccolo et al. 2005 figures and equations ###############################


##  Eqn #####################################################################



=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================

##  FIG #####################################################################



=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================

##  APPENDIX ################################################################



=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================


=============================================================================
