<html>
<script src="../../lib/colormaps.js"></script>
<script src="../../lib/gpgpu.js"></script>
<script src="../../lib/gpugaussian.js"></script>
<script src="../../lib/gpurand.js"></script>
<script src="../../lib/math.js"></script>
<script src="../../lib/complex_macros.js"></script>
<script src="../../lib/complex_parser.js"></script>
<script src="../../lib/sprintf.js"></script>
<script src="./perceptron_cursors.js"></script>

<script id="conformal-perceptron" type="x-shader/x-fragment">
/**

Perceptron pseudocode flowchart:

main conformal mapping shader:

    sample-point: apply complex conformal map to screen-point
    self-sample: get screen data (with boundary conditions applied)
    aux-sample: get auxiliary buffer data (typically an image texture)
    composit: map (self-sample,aux-sample,location) --> sample
        this includes a window and gradient defined by target pooint
    apply mask/window/gradient 
        additive/multiplicative color transforms that depend on 
        screen-point (not sample-point)
    apply contrast-brightness filter
    apply hue-saturation filter
**/
// input buffers
uniform sampler2D buff;
uniform sampler2D aux;
uniform sampler2D noise;

// free parameters
uniform vec2 w; // translation
uniform vec2 v; // rotation/scaling
uniform vec2 u; // gradient parameter

uniform float lnoise;// = 0.0;
uniform float mblur; // = 0.1;
    
#define COMPLEX_PLANE_SCALE 2.0

// We'll define this later? 
//vec2 complex_map(vec2 z) {
//    return cmul(z,z);
//}

#define SOFTHRESH(x) (1.0/(1.0+exp(x)))

void main() {
    /////////////////////////////////////////////////////////////////
    // Compute important parameters

    // Create vector for compensating for non-square aspect ratio
    vec2 scale = vec2(W<H?W:H,W<H?W:H);
    vec2 truescale = vec2(W,H);
    vec2 rescale = truescale/scale;

    // Get source location: map screen into [0,1]x[0,1]
    vec2 p0 = gl_FragCoord.xy/truescale; 

    // Convert to complex plane
    vec2 z0 = p0*(2.0*COMPLEX_PLANE_SCALE)-COMPLEX_PLANE_SCALE;
    // aspect ratio fudge factor
    z0 = z0*rescale;

    // Apply complex map (rotate, map, shift)
    vec2 z  = cdiv(z0,v);
    z = complex_map(z);
    vec2 z1 = z+w;

    // aspect ratio fudge factor
    z1 = z1/rescale;
    // Convert back to image coordinates
    vec2 p1 = (z1+COMPLEX_PLANE_SCALE)/(2.0*COMPLEX_PLANE_SCALE);
    // Compute radius of on-screen point
    float r0 = length(z0);
    // Compute radius of sample point
    float r1 = length(z1);

    // tiled    
    p0 = mod(p0,1.0);
    p1 = mod(p1,1.0);

    // mirrored
    //p0 = 1.0-abs(mod(p0,2.0)-1.0);
    //p1 = 1.0-abs(mod(p1,2.0)-1.0);

    // Clamped
    //p0 = clamp(p0,0.0,1.0);
    //p1 = clamp(p1,0.0,1.0);

    /////////////////////////////////////////////////////////////////
    // Perform texture fetches
    vec3 c0 = texture2D(buff ,p0).rgb; // original color
    vec3 c1 = texture2D(buff ,p1).rgb; // conformal mapped color
    vec3 cA = vec3(1,1,1);//texture2D(aux  ,p1).rgb; // background ("aux") color
    vec3 cN = texture2D(noise,p0).rgb; // noise texture
    
/*

    /// Experiment: do color transform on c0 here
    // Apply brightness
    c0  = c0+brightness*0.5+(0.5-c0)*abs(brightness);
    // Apply contrast 
    c0  = (c0-0.5)*tan((contrast+1.0)*0.78539816339)+0.5;
    // Apply hue and saturation via hue-chroma linear transform
    c0 = hs.z*c0.rgb + (hs.x+hs.y)*c0.gbr + (hs.x-hs.y)*c0.brg;
    // done
    */

    // default to black gradient for now (could be another texture?)
    vec3 cG = vec3(0,0,0); 
    
    // No bounds test
    float mask = 0.0;
    
    // Hard fade for out of bounds
    //float mask = float(r0>2.0);
    
    // Soft fade for out of bounds
    //float mask = SOFTHRESH((2.0-r0)*10.0);
    
    // Composit color with aux buffer: handles out-of-bounds pixels
    mask = clamp(mask,0.0,1.0);
    vec3 c = mask*cA+(1.0-mask)*c1;

    float gradient = pow(SOFTHRESH((u.x+1.0-r0)*u.y*10.0),1.0);

    // Fade to gradient
    gradient = clamp(gradient,0.0,1.0);
    c = (1.0-gradient)*c + gradient*cG;

    // Add noise
    c = lnoise*(cN-0.5) + c;

    // motion blur
    c = mblur*c0+(1.0-mblur)*c;

    // done
    gl_FragColor = vec4(c,0);
}
</script>


<script id="convolutional-perceptron" type="x-shader/x-fragment">
/*
convolutional shader: 

    unsharp/blur kernel with parameter in +- 1
    laplacian? Edge enhance? Unclear
    General image filters go here
*/
uniform sampler2D blur; // blurred buffer
uniform sampler2D buff; // raw buffer
uniform float hue;
uniform float saturation;
uniform float contrast;
uniform float brightness;
uniform float blursharp;
void main() {
    // Get source location
    vec2 p0 = gl_FragCoord.xy/vec2(W,H); 
    // get RGBA data from all buffers
    vec3 colorblur = texture2D(blur,p0).rgb;
    vec3 colorbuff = texture2D(buff,p0).rgb;
    vec3 c = colorbuff;
    // Perform unsharp masking / gaussian blurring
    // if 0>blursharp>-1 then this acts like an unsharp mask
    // if 1>blursharp>0  then this acts like a gaussian blur
    c  = (1.0-blursharp)*c+blursharp*colorblur;
    // Apply brightness
    c  = c+brightness*0.5+(0.5-c)*abs(brightness);
    // Apply contrast 
    c  = (c-0.5)*tan((contrast+1.0)*0.78539816339)+0.5;
    // Apply hue and saturation via hue-chroma linear transform
    float alpha = saturation*cos(hue);
    float beta  = saturation*sin(hue);
    float hsx = (0.50-alpha)/1.50;
    float hsy = beta*1.15470053838;
    c = ((0.25+alpha)/0.75)*c.rgb + (hsx+hsy)*c.gbr + (hsx-hsy)*c.brg;
    // done
    gl_FragColor = vec4(c,0); 
}
</script>
</script>


<script>

is_fullscreen = false;
function get_fullscreen() {
    //using HTML5 for fullscreen (only newest Chrome + FF)
    //canvas.webkitRequestFullScreen(Element.ALLOW_KEYBOARD_INPUT); //Chrome
    //canvas.mozRequestFullScreen(); //Firefox
    document.fullscreenEnabled = document.fullscreenEnabled || document.mozFullScreenEnabled || document.documentElement.webkitRequestFullScreen;
    function requestFullscreen(element) {
        if (element.requestFullscreen) {
            console.log(element.requestFullscreen());
        } else if (element.mozRequestFullScreen) {
            console.log(element.mozRequestFullScreen());
        } else if (element.webkitRequestFullScreen) {
            console.log(element.webkitRequestFullScreen(Element.ALLOW_KEYBOARD_INPUT));
        }
    }
    console.log('full screen support: ' +document.fullscreenEnabled);
    if (document.fullscreenEnabled) {
        requestFullscreen(document.documentElement);
    }
    requestFullscreen(canvas);
    is_fullscreen = 'maybe';
}


// preload images
var images     = {};
var imagefiles = ['tulip.png','sprites.png'];

function load_images() {
    console.log('loading');
    var loaded=0;
    for (var i=0;i<imagefiles.length;i++) {
        var temp = new Image();
        temp.onload = function(){
            // the only reason this isn't a race is that Javascript is 
            // single threaded and events are queued for processing
            loaded+=1;
            if (loaded==imagefiles.length) {
                console.log('images loaded');
                main();
            }
        };
        var name = imagefiles[i];
        images[name] = temp;
        temp.src = name;
    }
}

// This is the main script that will run when the website loads
function main()
{
    console.log('starting');
    var tulip   = images['tulip.png'];
    var sprites = images['sprites.png'];

    // Retrieve a handle to the canvas element
    var canvas = $("maincanvas");

    // Get canvas location so we can find the mouse location
    var rect = canvas.getBoundingClientRect();

    // Change canvas pointer style
    canvas.style.cursor = "crosshair";

    // Create a WebGL context on the canvas, abort if fail
    var gl = getRasterGL(canvas);
    if (!gl) OUT;
    
    // Images to texture
    var sprites_img    = image_texture(gl,sprites); 
    var background_img = image_texture(gl,tulip);   
    
    // Create complex map? 
    var map = 'z^2';
    var map = math.parse(map).transform(complex_macro_transform)._toString();
    var complex_map = "\n\n#define complex_map(z) ("+map+")\n\n";
    console.log('complex map: '+complex_map);
    var header = complex_macros + complex_map;
    console.log('full header: '+header);

    // Initialize GPU shader functions
    console.log('initializing shaders');
    var img    = image_texture(gl,tulip);
    var conv   = getRasterProgram(gl,'convolutional-perceptron',[],header);
    var map    = getRasterProgram(gl,'conformal-perceptron',[],header);
    var copy   = GPUcopy(gl);
    var blur   = GPUGaussianBlur(gl,1.0);

    // Initialize memory buffers
    console.log('initializing buffers');
    var buff0 = newBasicFramebuffer(gl,{wrap:gl.MIRRORED_REPEAT});
    var buff1 = newBasicFramebuffer(gl,{wrap:gl.MIRRORED_REPEAT});
    var buff2 = newBasicFramebuffer(gl,{wrap:gl.MIRRORED_REPEAT});
    var buff3 = newBasicFramebuffer(gl,{wrap:gl.MIRRORED_REPEAT});
    console.log('initializing buffers done');
    
    // Prepare GPU random number generator
    console.log('initializing RNG');
    var gpurng = GPUNoise(gl);
    var noise  = newBasicFramebuffer(gl,{wrap:gl.REPEAT});
    gpurng.randomize(noise);
    console.log('initializing RNG done');

    console.log('initial state');
    copy(background_img,buff0);
    copy(background_img,buff2);

    // Initialize cursor handler program
    var npoint = 7; // Number of cursors (no more than 11)
    var ndots  = 5; // Number of trailing dots per cursor, plus one
    var render_cursors = sprite_renderer(gl,npoint,ndots,canvas);

    // Add (experimental) key event listener
    // Plan: key events are passed as compile-time arguments and trigger
    // a shader rebuild. 
    // So, we need to model of the discrete arguments to perceprton
    // Most of these will be enum times: a finite set of (named) options
    // that keys cycle through. 
    // 
    // Note: how might one access this on a tablet? Hmm! Build a mouse 
    // interface? reuse the old javascript interface? Draw an interface on
    // top? 
    // 
    // Perceptron options should be defined by JSON though, for ease. 
    var poptions = {
        screen_mask:['none','radial','linear','circle','edge'],
        camera_mask:['none','radial','linear','circle','edge'],
        repeat_mode:['extend','tile','mirrored'],
        screen_mask_source:['screen','aux','color A','color B'],
        camera_mask_source:['screen','aux','color A','color B'],
        aux_source:['image','webcam','youtube'],
        map:['z','z*z','z^2'],
        cursors:[true,false],
        invert:[true,false],
        blursharp_on:[true,false],
        huesat_on:[true,false],
        conbright_on:[true,false],
    };
    
    // then a preset looks like this? 
    var poption_set = {
        screen_mask:[0,'none'],
        image:'tulip.png',
    };

    // Notes on expression parsing
    // Get the math.js library
    // use math.parse to get expression tree
    // expression tree objects, important details: 
    //      type: string: ParenthesisNode, OperatorNode
    //      isNode: true if internal node, false if leaf
    //      isOperatorNode: ?
    //      isParenthesisNode: have one field "content"
    //      args: array, subexpression objects if node

    document.onkeypress = function(e) {
        var k = (e.which) ? e.which : e.keyCode;
        console.log('Key pressed: '+k);
        // Common key codes (not exclusive)
        // # denotes numeric keypad codes (distinct from numbers in a row
        // above QWERTYy.
        switch (k) {
            case  8: /*BACKSP*/ break;
            case  9: /*TAB*/ break;
            case 13: /*ENTER*/ break;
            case 16: /*SHFT*/ break;
            case 17: /*CTRL*/ break;
            case 18: /*ALT*/ break;
            case 19: /*PAUSE*/ break;
            case 20: /*CAPS*/ break;
            case 27: /*ESC*/ break;
            case 32: /*SPACE*/ break;
            case 33: /*PGUP*/ break;
            case 34: /*PGDOWN*/ break;
            case 35: /*END*/ break;
            case 36: /*HOME*/ break;
            case 37: /*LEFT*/ break;
            case 38: /*RIGHT*/ break;
            case 39: /*UP*/ break;
            case 40: /*DOWN*/ break;
            case 42: /*PRINTSC*/ break;
            case 45: /*INS*/ break;
            case 46: /*DEL*/ break;
            case 91: /*LEFTWIN*/ break;
            case 92: /*RIGHTWIN*/ break;
            case 93: /*SELECT*/ break;
            case 144: /*NUMLOCK*/ break;
            case 145: /*SCROLLLOCK*/ break;

            case 126: /*~*/ break;
            case 33: /*!*/ break;
            case 64: /*@*/ break;
            case 35: /*#*/ break;
            case 36: /*$*/ break;
            case 37: /*%*/ break;
            case 94: /*^*/ break;
            case 38: /*&*/ break;
            case 42: /***/ break;
            case 106: /*#**/ break;
            case 40: /*(*/ break;
            case 41: /*)*/ break;
            case 95: /*_*/ 
            break;

            case 43: /*+*/ 
            // only applies to keydown? otherwise a letter? case 107: /*#+*/ 
            break;

            case 48 : /*0*/ 
            // only applies to keydown? otherwise a letter? case 96 : /*#0*/    
            break;
            case 49 : /*1*/ 
            // only applies to keydown? otherwise a letter? case 97 : /*#1*/ 
            break;
            case 50 : /*2*/ 
            // only applies to keydown? otherwise a letter? case 98 : /*#2*/ 
            break;
            case 51 : /*3*/ 
            // only applies to keydown? otherwise a letter? case 99 : /*#3*/ 
            break;
            case 52 : /*4*/ 
            // only applies to keydown? otherwise a letter? case 100: /*#4*/ 
            break;
            case 53 : /*5*/ 
            // only applies to keydown? otherwise a letter? case 101: /*#5*/ 
            break;
            case 54 : /*6*/ 
            // only applies to keydown? otherwise a letter? case 102: /*#6*/ 
            break;
            case 55 : /*7*/ 
            // only applies to keydown? otherwise a letter? case 103: /*#7*/ 
            break;
            case 56 : /*8*/ 
            // only applies to keydown? otherwise a letter? case 104: /*#8*/ 
            break;
            case 57 : /*9*/ 
            // only applies to keydown? otherwise a letter? case 105: /*#9*/ 
            break;

            case 97 : /*a*/ break;
            case 65 : /*A*/ break;
            case 98 : /*b*/ break;
            case 66 : /*B*/ break;
            case 99 : /*c*/ break;
            case 67 : /*C*/ break;
            case 100: /*d*/ break;
            case 68 : /*D*/ break;
            case 101: /*e*/ break;
            case 69 : /*E*/ break;
            case 102: /*f*/ break;
            case 70 : /*F*/ break;
            case 103: /*g*/ break;
            case 71 : /*G*/ break;
            case 104: /*h*/ break;
            case 72 : /*H*/ break;
            case 105: /*i*/ break;
            case 73 : /*I*/ break;
            case 106: /*j*/ break;
            case 74 : /*J*/ break;
            case 107: /*k*/ break;
            case 75 : /*K*/ break;
            case 108: /*l*/ break;
            case 76 : /*L*/ break;
            case 109: /*m*/ break;
            case 77 : /*M*/ break;
            case 110: /*n*/ break;
            case 78 : /*N*/ break;
            case 111: /*o*/ break;
            case 79 : /*O*/ break;
            case 112: /*p*/ break;
            case 80 : /*P*/ break;
            case 113: /*q*/ break;
            case 81 : /*Q*/ break;
            case 114: /*r*/ break;
            case 82 : /*R*/ break;
            case 115: /*s*/ break;
            case 83 : /*S*/ break;
            case 116: /*t*/ break;
            case 84 : /*T*/ break;
            case 117: /*u*/ break;
            case 85 : /*U*/ break;
            case 118: /*v*/ break;
            case 86 : /*V*/ break;
            case 119: /*w*/ break;
            case 87 : /*W*/ break;
            case 120: /*x*/ break;
            case 88 : /*X*/ break;
            case 121: /*y*/ break;
            case 89 : /*Y*/ break;
            case 122: /*z*/ break;
            case 90 : /*Z*/ break;

            case 112: /*F1*/ break;
            case 113: /*F2*/ break;
            case 114: /*F3*/ break;
            case 115: /*F4*/ break;
            case 116: /*F5*/ break;
            case 117: /*F6*/ break;
            case 118: /*F7*/ break;
            case 119: /*F8*/ break;
            case 120: /*F9*/ break;
            case 121: /*F10*/ break;
            case 122: /*F11*/ break;
            case 123: /*F12*/ break;

            case 186: /*;*/ break;
            case 187: /*=*/ break;
            case 188: /*,*/ break;
            case 189: /*-*/ break;
            case 108: /*#-*/ break;
            case 190: /*.*/ break;
            case 109: /*#.*/ break;
            case 191: /*/*/ break;
            case 110: /*#/*/ break;
            case 192: /*\*/ break;
            case 193: /*`*/ break;
            case 194: /*[*/ break;
            case 195: /*]*/ break;
            case 196: /*'*/ break;
            
            // OSX can generate many more key-typed events
            // including combinind modifiers, etc. 
            // they are not documented here. 
        }
    };

    console.log('starting animation');
    var FPS = 25.0;
    function animate() {
        setTimeout(function(){
            // draw new "random" numbers
            gpurng(noise,buff3);
            
            translate = render_cursors.get(0);
            rotate    = render_cursors.get(1);
            effects   = render_cursors.get(2);
            huesatu   = render_cursors.get(3);
            conbrit   = render_cursors.get(4);
            blrshrp   = render_cursors.get(5);
            gradient  = render_cursors.get(6);

            // Pre compute hue-saturation matrix for performance reasons
            /*
            var alpha = huesatu.y*Math.cos(hue);
            var beta  = huesatu.y*Math.sin(hue);
            var hsx = (0.50-alpha)/1.50;
            var hsy = beta*1.15470053838;
            var hsz = ((0.25+alpha)/0.75);
            */
            
            // Apply conformal perceptron
            map({buff:buff1,
                 aux:background_img,
                 noise:buff3,
                 lnoise:effects.x,
                 mblur:effects.y,
                 u:[gradient.x,gradient.y], // translation
                 w:[translate.x,translate.y], // translation
                 v:[rotate.x*2.0,2.0*rotate.y]},buff2) // rotation/scaling
            
            // TODO: apply a display mask / processing filter
            copy(buff2,buff1);

            // Render cursors on top
            render_cursors(buff1,sprites_img,buff2);

            // Show current result on the screen
            copy(buff2);
            copy(buff2,buff1);

            // The convolutional / color perceptron is commented out
            // it takes too long to run
            /*
            // Take the result and blur it into a new buffer
            blur(buff2,buff1,buff3);
            // Apply the convolutional and color-morph shader
            conv({buff:buff2,
                  blur:buff3,
                  hue:huesatu.x,
                  saturation:huesatu.y,
                  contrast:conbrit.x,
                  brightness:conbrit.y,
                  blursharp:blrshrp.x},
                  buff1);
            */
            //console.log(buff2.readPixels(gl.width/2,gl.height/2,4,4));
            requestAnimationFrame(animate);
        },1000./FPS);
    }
    animate();
}
//<canvas id='maincanvas' style="width:800px;height:800px;"></canvas>
</script>
<body onload="javascript:load_images()" style="margin:0;overflow:hidden;">
<canvas id='maincanvas' style="width:640px;height:480px;"></canvas>
</body>
</html>
